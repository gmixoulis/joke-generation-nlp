# NLP Research: Humor Generation & Analysis

## ğŸ¤– Project Overview

**Humor Generation NLP** is a research-oriented project exploring the linguistic capabilities of machine learning models. It compares various architectures (LSTM, RNN) in the task of generating coherent, humorous text, and includes a classification pipeline to assess the "funniness" of the output.

## ğŸ”‘ Key Features

- **Generative Models**: Experiments with sequence-to-sequence models for text creation.
- **Sentiment Classification**: Binary and multi-class classification models to analyze dataset quality.
- **Data Engineering**: Pipelines for cleaning and tokenizing large text corpora (`preprocessing/`).
- **Reproducibility**: Structured codebase separating data, model definition, and training loops.

## ğŸ› ï¸ Tech Stack & Skills

- **Language**: Python
- **Libraries**: TensorFlow / Keras, NLTK, Pandas
- **Data Science**: Text Preprocessing, Model Evaluation (sacreBLEU, Accuracy)
- **Domain**: Natural Language Processing (NLP), Computational Linguistics

## ğŸ’¡ Innovation

This project tackles the subtle nuances of **Computational Creativity**. By attempting to quantify and generate humor, it demonstrates advanced skills in NLP beyond standard sentiment analysis, touching on semantics and pragmatics.

## ğŸ“‚ Repository Structure

- `generation/`: Scripts for training generative models.
- `classification/`: Sentiment analysis classifiers.
- `preprocessing/`: Tokenization and cleaning utilities.
